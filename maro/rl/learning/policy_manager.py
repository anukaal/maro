# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

import time
from abc import ABC, abstractmethod
from collections import defaultdict
from multiprocessing import Pipe, Process
from os import getcwd
from typing import Callable, Dict, List

from maro.communication import Proxy, SessionMessage, SessionType
from maro.rl.policy import LossInfo, RLPolicy
from maro.rl.typing import Trajectory
from maro.rl.utils import MsgKey, MsgTag
from maro.utils import Logger


class AbsPolicyManager(ABC):
    """Manage all policies.

    The actual policy instances may reside here or be distributed on a set of processes or remote nodes.

    Args:
        policies (List[RLPolicy]): A list of ``RLPolicy`` instances.
    """
    def __init__(self):
        super().__init__()
        self.update_count = 0

    @property
    def version(self):
        return self.update_count

    @abstractmethod
    def update(self, rollout_info: Dict[str, list]):
        """Logic for handling incoming experiences is implemented here."""
        raise NotImplementedError

    @abstractmethod
    def get_state(self):
        raise NotImplementedError


class SimplePolicyManager(AbsPolicyManager):
    """Policy manager that contains the actual policy instances.

    Args:
        create_policy_func_dict (dict): A dictionary mapping policy names to functions that create them. The policy
            creation function should have policy name as the only parameter and return an ``RLPolicy`` instance.
        warmup (Dict[str, int]): A dictionary of (policy_name, warmup_size), where "warmup_size" indicates the
            minimum number of experiences in the experience memory required to trigger a call to ``learn`` for
            each policy. Defaults to None, in which case all warm-up sizes will be set to 1.
        log_dir (str): Directory to store logs in. A ``Logger`` with tag "POLICY_MANAGER" will be created at init
            time and this directory will be used to save the log files generated by it. Defaults to the current
            working directory.
    """
    def __init__(
        self,
        create_policy_func_dict: Dict[str, Callable],
        parallel: bool = False,
        log_dir: str = getcwd()
    ):
        super().__init__()
        self._policy_names = list(create_policy_func_dict.keys())
        self._parallel = parallel
        self._logger = Logger("SIMPLE_POLICY_MANAGER", dump_folder=log_dir)
        if self._parallel:
            self._logger.info("Spawning policy host processes")
            self._state_cache = {}
            self._policy_hosts = []
            self._manager_end = {}

            def _policy_host(name, create_policy_func, conn):
                policy = create_policy_func(name)
                conn.send({"type": "init", "policy_state": policy.get_state()})
                while True:
                    msg = conn.recv()
                    if msg["type"] == "learn":
                        info_list = msg["rollout_info"]
                        if isinstance(info_list[0], Trajectory):
                            policy.learn_from_multi_trajectories(info_list)
                        elif isinstance(info_list[0], LossInfo):
                            policy.apply(info_list)
                        else:
                            raise TypeError(
                                f"Roll-out information must be of type 'Trajectory' or 'LossInfo', "
                                f"got {type(info_list[0])}"
                            )
                        conn.send({"type": "learn_done", "policy_state": policy.get_state()})
                    elif msg["type"] == "quit":
                        break

            for name, create_policy_func in create_policy_func_dict.items():
                manager_end, policy_end = Pipe()
                self._manager_end[name] = manager_end
                host = Process(target=_policy_host, args=(name, create_policy_func, policy_end))
                self._policy_hosts.append(host)
                host.start()

            for policy_name, conn in self._manager_end.items():
                msg = conn.recv()
                if msg["type"] == "init":
                    self._state_cache[policy_name] = msg["policy_state"]
        else:
            self._logger.info("local mode")
            self._policy_dict = {name: func(name) for name, func in create_policy_func_dict.items()}

    def update(self, rollout_info: Dict[str, list]):
        """Store experiences and update policies if possible.

        The incoming experiences are expected to be grouped by policy ID and will be stored in the corresponding
        policy's experience manager. Policies whose update conditions have been met will then be updated.
        """
        self._logger.info(f"parallel: {self._parallel}")
        if self._parallel:
            self._logger.info("I'm parallel")
            self._logger.info(f"received rollout info from policies {list(rollout_info.keys())}")
            for policy_name, info_list in rollout_info.items():
                self._manager_end[policy_name].send({"type": "train", "rollout_info": info_list})
            for policy_name, conn in self._manager_end.items():
                msg = conn.recv()
                if msg["type"] == "learn_done":
                    self._state_cache[policy_name] = msg["policy_state"]
        else:
            self._logger.info("I'm NOT parallel")
            self._logger.info(f"received rollout info from policies {list(rollout_info.keys())}")
            t0 = time.time()
            for policy_name, info_list in rollout_info.items():
                if isinstance(info_list[0], Trajectory):
                    self._logger.info("learning from multiple trajectories")
                    self._policy_dict[policy_name].learn_from_multi_trajectories(info_list)
                elif isinstance(info_list[0], LossInfo):
                    self._logger.info("learning from loss info")
                    self._policy_dict[policy_name].apply(info_list)

            self._logger.info(f"Updated policies {list(rollout_info.keys())}")

        self.update_count += 1
        self._logger.debug(f"policy update time: {time.time() - t0}")

    def get_state(self):
        if self._parallel:
            return self._state_cache
        else:
            return {name: policy.get_state() for name, policy in self._policy_dict.items()}

    def exit(self):
        """Tell the policy hosts to exit."""
        if self._parallel:
            for conn in self._manager_end.values():
                conn.send({"type": "quit"})


class DistributedPolicyManager(AbsPolicyManager):
    """Policy manager that communicates with a set of remote nodes for parallel training.

    Args:
        policy_dict (Dict[str, RLPolicy]): Policies managed by the manager.
        group (str): Group name for the training cluster, which includes all hosts and a policy manager that
            manages them.
        num_hosts (int): Number of hosts. The hosts will be identified by "POLICY_HOST.i", where 0 <= i < num_hosts.
        warmup (Dict[str, int]): A dictionary of (policy_name, warmup_size), where "warmup_size" indicates the
            minimum number of experiences in the experience memory required to trigger a call to ``learn`` for
            each policy. Defaults to None, in which case all warm-up sizes will be set to 1.
        log_dir (str): Directory to store logs in. A ``Logger`` with tag "POLICY_MANAGER" will be created at init
            time and this directory will be used to save the log files generated by it. Defaults to the current
            working directory.
        proxy_kwargs: Keyword parameters for the internal ``Proxy`` instance. See ``Proxy`` class
            for details. Defaults to the empty dictionary.
    """
    def __init__(
        self,
        policy_names: List[str],
        group: str,
        num_hosts: int,
        log_dir: str = getcwd(),
        proxy_kwargs: dict = {}
    ):
        super().__init__()
        self._policy_names = policy_names
        peers = {"policy_host": num_hosts}
        self._proxy = Proxy(group, "policy_manager", peers, component_name="POLICY_MANAGER", **proxy_kwargs)
        self._logger = Logger("MULTINODE_POLICY_MANAGER", dump_folder=log_dir)

        self._policy2host = {}
        self._host2policies = defaultdict(list)
        self._logger = Logger("MULTINODE_POLICY_MANAGER", dump_folder=log_dir)

        # assign policies to hosts
        for i, name in enumerate(self._policy_names):
            host_id = i % num_hosts
            self._policy2host[name] = f"POLICY_HOST.{host_id}"
            self._host2policies[f"POLICY_HOST.{host_id}"].append(name)

        # ask the hosts to initialize the assigned policies
        for host_name, policy_names in self._host2policies.items():
            self._proxy.send(SessionMessage(
                MsgTag.INIT_POLICIES, self._proxy.name, host_name, body={MsgKey.POLICY_NAMES: policy_names}
            ))

        # cache the initial policy states
        self._state_cache, dones = {}, 0
        for msg in self._proxy.receive():
            if msg.tag == MsgTag.INIT_POLICIES_DONE:
                for policy_name, policy_state in msg.body[MsgKey.POLICY_STATE].items():
                    self._state_cache[policy_name] = policy_state
                    self._logger.info(f"Policy {policy_name} initialized")
                dones += 1
                if dones == num_hosts:
                    break

    def update(self, rollout_info: Dict[str, list]):
        msg_dict = defaultdict(lambda: defaultdict(dict))
        for policy_name, info_list in rollout_info.items():
            host_id_str = self._policy2host[policy_name]
            msg_dict[host_id_str][MsgKey.ROLLOUT_INFO][policy_name] = info_list

        dones = 0
        self._proxy.iscatter(MsgTag.LEARN, SessionType.TASK, list(msg_dict.items()))
        for msg in self._proxy.receive():
            if msg.tag == MsgTag.LEARN_DONE:
                for policy_name, policy_state in msg.body[MsgKey.POLICY_STATE].items():
                    self._state_cache[policy_name] = policy_state
                dones += 1
                if dones == len(msg_dict):
                    break

        self.update_count += 1
        self._logger.info(f"Updated policies {list(rollout_info.keys())}")

    def get_state(self):
        return self._state_cache

    def exit(self):
        """Tell the remote policy hosts to exit."""
        self._proxy.ibroadcast("policy_host", MsgTag.EXIT, SessionType.NOTIFICATION)
        self._proxy.close()
        self._logger.info("Exiting...")
